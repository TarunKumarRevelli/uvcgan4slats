{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# UVCGAN Training on Google Colab\n",
        "\n",
        "This notebook trains UVCGAN on BRATS19 dataset using Colab's free GPU.\n",
        "\n",
        "**Before starting:**\n",
        "1. Enable GPU: Runtime → Change runtime type → Hardware accelerator: GPU\n",
        "2. Upload your BRATS19 dataset to Google Drive or prepare to upload it here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0: Quick Pipeline Test (Optional - Recommended First!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick test to verify pipeline works before full training\n",
        "# This runs 1 epoch each of pretraining and training (~5-10 minutes)\n",
        "# Uncomment to run:\n",
        "\n",
        "# !python scripts/brats19/quick_test.py \\\n",
        "#     --pretrain-epochs 1 \\\n",
        "#     --train-epochs 1 \\\n",
        "#     --batch-size 4\n",
        "\n",
        "print(\"Quick test cell ready. Uncomment the command above to run a test.\")\n",
        "print(\"This verifies the entire pipeline works before committing GPU hours to full training.\")\n",
        "print(\"\\nOr use the simpler test script:\")\n",
        "print(\"  python scripts/brats19/quick_test.py\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install PyTorch with CUDA support\n",
        "# Using CUDA 11.8 for compatibility (works with most Colab GPUs)\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install numpy pillow matplotlib tqdm gitpython\n",
        "\n",
        "# Verify PyTorch installation\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Clone and Install Repositories\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2.5: Apply Fixes (Scheduler, Grayscale, Config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone uvcgan4slats\n",
        "!git clone https://github.com/LS4GAN/uvcgan4slats.git\n",
        "%cd uvcgan4slats\n",
        "\n",
        "# Clone and install toytools\n",
        "!git clone https://github.com/LS4GAN/toytools\n",
        "%cd toytools\n",
        "!pip install -e .\n",
        "%cd ..\n",
        "\n",
        "# Install uvcgan4slats\n",
        "!pip install -e .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Mount Google Drive (Optional - if dataset is on Drive)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy dataset from Drive (modify path as needed)\n",
        "# !cp -r /content/drive/MyDrive/brats19 /content/brats19\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Set Environment Variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set data and output directories\n",
        "os.environ['UVCGAN_DATA'] = '/content'\n",
        "os.environ['UVCGAN_OUTDIR'] = '/content/outputs'\n",
        "\n",
        "# Verify\n",
        "print(f\"Data directory: {os.environ['UVCGAN_DATA']}\")\n",
        "print(f\"Output directory: {os.environ['UVCGAN_OUTDIR']}\")\n",
        "\n",
        "# Check if dataset exists\n",
        "if os.path.exists('/content/brats19'):\n",
        "    print(\"✓ Dataset found\")\n",
        "    !ls -la /content/brats19\n",
        "else:\n",
        "    print(\"✗ Dataset not found. Please upload or mount your dataset.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Verify GPU Availability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Run Pretraining (Optional but Recommended)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pretrain generators\n",
        "# Adjust batch_size based on GPU memory (32 or 16 if OOM errors)\n",
        "!python scripts/brats19/pretrain_brats19.py --gen uvcgan --batch_size 32\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Run Main Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train translation model\n",
        "# If you skipped pretraining, add --no-pretrain flag\n",
        "!python scripts/brats19/train_brats19.py --gen uvcgan --labmda-cycle 1.0 --lr-gen 1e-5 --lr-disc 5e-5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Visualize Results (After Training)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize results from a specific checkpoint\n",
        "import os\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Find the latest checkpoint directory\n",
        "checkpoint_base = '/content/outputs/brats19'\n",
        "checkpoint_dirs = [d for d in os.listdir(checkpoint_base) if d.startswith('model_m')]\n",
        "\n",
        "if checkpoint_dirs:\n",
        "    # Use the training checkpoint (not pretrain)\n",
        "    train_checkpoints = [d for d in checkpoint_dirs if 'train' in d]\n",
        "    if train_checkpoints:\n",
        "        checkpoint_dir = os.path.join(checkpoint_base, sorted(train_checkpoints)[-1])\n",
        "        print(f\"Using checkpoint: {checkpoint_dir}\")\n",
        "        \n",
        "        # Evaluate and visualize\n",
        "        import subprocess\n",
        "        result = subprocess.run([\n",
        "            'python', 'scripts/brats19/eval_and_visualize.py',\n",
        "            checkpoint_dir,\n",
        "            '--n-samples', '10',\n",
        "            '--split', 'test'\n",
        "        ], capture_output=True, text=True)\n",
        "        \n",
        "        print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(\"Errors:\", result.stderr)\n",
        "        \n",
        "        # Display sample visualizations\n",
        "        vis_dir = os.path.join(checkpoint_dir, 'visualizations', 'fake_vs_real')\n",
        "        if os.path.exists(vis_dir):\n",
        "            images = sorted(glob.glob(os.path.join(vis_dir, '*.png')))\n",
        "            print(f\"\\nFound {len(images)} visualization images\")\n",
        "            \n",
        "            for img_path in images[:5]:  # Show first 5\n",
        "                print(f\"\\n{os.path.basename(img_path)}:\")\n",
        "                display(Image(img_path))\n",
        "        else:\n",
        "            print(\"Visualizations not found. Make sure eval_and_visualize.py completed successfully.\")\n",
        "    else:\n",
        "        print(\"No training checkpoints found. Run training first.\")\n",
        "else:\n",
        "    print(\"No checkpoints found. Run training first.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Save Results to Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save outputs to Drive\n",
        "!mkdir -p /content/drive/MyDrive/uvcgan_outputs\n",
        "!cp -r /content/outputs /content/drive/MyDrive/uvcgan_outputs/\n",
        "print(\"Results saved to Google Drive!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
